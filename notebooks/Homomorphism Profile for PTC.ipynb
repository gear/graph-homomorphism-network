{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "from utils import load_data, nx2gt\n",
    "from graph_tool.all import motifs, Graph\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "# classes: 2\n",
      "# maximum node tag: 19\n",
      "# data: 344\n"
     ]
    }
   ],
   "source": [
    "ptc_graphs = load_data(\"PTC\", degree_as_tag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_g = nx2gt(ptc_graphs[0][6].g)\n",
    "# Workaround to allow parallel motifs\n",
    "idx = test_g.vertex_index.copy(\"int\")\n",
    "shuffle(idx.a)\n",
    "test_g = Graph(test_g, vorder=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph object, undirected, with 29 vertices and 31 edges at 0x7fa9b2613e48>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_5 = [nx2gt(f) for f in nx.generators.nonisomorphic_trees(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.16 ms, sys: 0 ns, total: 1.16 ms\n",
      "Wall time: 1.17 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<Graph object, undirected, with 5 vertices and 4 edges at 0x7fa9b2613d68>,\n",
       "  <Graph object, undirected, with 5 vertices and 4 edges at 0x7fa9b27dea90>,\n",
       "  <Graph object, undirected, with 5 vertices and 4 edges at 0x7fa9b27de860>],\n",
       " [1, 77, 108])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "motifs(g=test_g, k=5, p=1.0, motif_list=trees_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_7 = [nx2gt(f) for f in nx.generators.nonisomorphic_trees(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.07 ms, sys: 133 µs, total: 6.21 ms\n",
      "Wall time: 5.74 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<Graph object, undirected, with 7 vertices and 6 edges at 0x7fa9b2622470>,\n",
       "  <Graph object, undirected, with 7 vertices and 6 edges at 0x7fa9b2606cf8>,\n",
       "  <Graph object, undirected, with 7 vertices and 6 edges at 0x7fa9b2606710>,\n",
       "  <Graph object, undirected, with 7 vertices and 6 edges at 0x7fa9b2606240>,\n",
       "  <Graph object, undirected, with 7 vertices and 6 edges at 0x7fa9b2606b00>,\n",
       "  <Graph object, undirected, with 7 vertices and 6 edges at 0x7fa9b2606358>,\n",
       "  <Graph object, undirected, with 7 vertices and 6 edges at 0x7fa9b2606518>,\n",
       "  <Graph object, undirected, with 7 vertices and 6 edges at 0x7fa9b260e048>,\n",
       "  <Graph object, undirected, with 7 vertices and 6 edges at 0x7fa9b26060b8>,\n",
       "  <Graph object, undirected, with 7 vertices and 6 edges at 0x7fa9b2606908>,\n",
       "  <Graph object, undirected, with 7 vertices and 6 edges at 0x7fa9b260e470>],\n",
       " [0, 0, 1, 4, 0, 30, 114, 123, 264, 52, 140])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "motifs(g=test_g, k=7, p=1.0, motif_list=trees_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Homomorphism profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_2 = [nx2gt(f) for f in nx.generators.nonisomorphic_trees(2)]\n",
    "trees_3 = [nx2gt(f) for f in nx.generators.nonisomorphic_trees(3)]\n",
    "trees_4 = [nx2gt(f) for f in nx.generators.nonisomorphic_trees(4)]\n",
    "trees_5 = [nx2gt(f) for f in nx.generators.nonisomorphic_trees(5)]\n",
    "trees_6 = [nx2gt(f) for f in nx.generators.nonisomorphic_trees(6)]\n",
    "trees_7 = [nx2gt(f) for f in nx.generators.nonisomorphic_trees(7)]\n",
    "\n",
    "all_trees = [trees_2, trees_3, trees_4, trees_5, trees_6, trees_7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.64 s, sys: 3.34 ms, total: 2.64 s\n",
      "Wall time: 2.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = []\n",
    "y = []\n",
    "for g in ptc_graphs[0]:\n",
    "    gt = nx2gt(g.g)\n",
    "    profile = []\n",
    "    for i, trees in enumerate(all_trees):\n",
    "        profile.extend(motifs(g=gt, k=i+2, p=1.0, motif_list=trees)[1])\n",
    "    X.append(profile)\n",
    "    y.append(g.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (E1) GIN Splits with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.8325548883169701\n",
      "Test:  0.4631578947368421\n",
      "Train:  0.8440643863179076\n",
      "Test:  0.6621499548328816\n",
      "Train:  0.8448200573004867\n",
      "Test:  0.6739319965126417\n",
      "Train:  0.8539552015075592\n",
      "Test:  0.6146469049694856\n",
      "Train:  0.8438876998615134\n",
      "Test:  0.6146469049694856\n",
      "Train:  0.8459488892883198\n",
      "Test:  0.6091954022988506\n",
      "Train:  0.8316132536664856\n",
      "Test:  0.5882352941176471\n",
      "Train:  0.8187616263619453\n",
      "Test:  0.6739319965126417\n",
      "Train:  0.8600657155754312\n",
      "Test:  0.5490716180371353\n",
      "Train:  0.8243736623442024\n",
      "Test:  0.6693191865605659\n",
      "Final avg:  0.6118287153548178\n",
      "CPU times: user 817 ms, sys: 2.77 ms, total: 820 ms\n",
      "Wall time: 813 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_avg = []\n",
    "for i in range (1,11):\n",
    "    with open(\"../data/PTC/10fold_idx/test_idx-{}.txt\".format(i), \"r\") as test_f,\\\n",
    "         open(\"../data/PTC/10fold_idx/train_idx-{}.txt\".format(i), \"r\") as train_f:\n",
    "        train_idx = [int(i) for i in train_f.readlines()]\n",
    "        test_idx = [int(i) for i in test_f.readlines()]\n",
    "        X_train = [X[i] for i in train_idx]\n",
    "        X_test = [X[i] for i in test_idx]\n",
    "        y_train = [y[i] for i in train_idx]\n",
    "        y_test = [y[i] for i in test_idx]\n",
    "        normalizer = Normalizer().fit(X_train)\n",
    "        X_train = normalizer.transform(X_train)\n",
    "        X_test = normalizer.transform(X_test)\n",
    "    clf = svm.SVC(C=100.0, kernel='poly', degree=6, gamma='scale', \n",
    "              coef0=0.0, shrinking=True, probability=False, tol=0.001, \n",
    "              cache_size=200, class_weight=None, verbose=False, max_iter=-1, \n",
    "              decision_function_shape='ovr', random_state=None)\n",
    "    clf.fit(X_train, y_train)  \n",
    "    print(\"Train: \", f1_score(y_pred=clf.predict(X_train), y_true=y_train, average='macro'))\n",
    "    print(\"Test: \", f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro'))\n",
    "    test_avg.append(f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro'))\n",
    "print(\"Final avg: \", sum(test_avg)/10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.8354838709677419\n",
      "Test:  0.47058823529411764\n",
      "Train:  0.8451612903225807\n",
      "Test:  0.6764705882352942\n",
      "Train:  0.8483870967741935\n",
      "Test:  0.6764705882352942\n",
      "Train:  0.8580645161290322\n",
      "Test:  0.6176470588235294\n",
      "Train:  0.8451612903225807\n",
      "Test:  0.6176470588235294\n",
      "Train:  0.8483870967741935\n",
      "Test:  0.6176470588235294\n",
      "Train:  0.8354838709677419\n",
      "Test:  0.5882352941176471\n",
      "Train:  0.8225806451612904\n",
      "Test:  0.6764705882352942\n",
      "Train:  0.8612903225806452\n",
      "Test:  0.5588235294117647\n",
      "Train:  0.8258064516129032\n",
      "Test:  0.6764705882352942\n",
      "Final avg:  0.6176470588235294\n",
      "CPU times: user 822 ms, sys: 46 µs, total: 822 ms\n",
      "Wall time: 816 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_avg = []\n",
    "for i in range (1,11):\n",
    "    with open(\"../data/PTC/10fold_idx/test_idx-{}.txt\".format(i), \"r\") as test_f,\\\n",
    "         open(\"../data/PTC/10fold_idx/train_idx-{}.txt\".format(i), \"r\") as train_f:\n",
    "        train_idx = [int(i) for i in train_f.readlines()]\n",
    "        test_idx = [int(i) for i in test_f.readlines()]\n",
    "        X_train = [X[i] for i in train_idx]\n",
    "        X_test = [X[i] for i in test_idx]\n",
    "        y_train = [y[i] for i in train_idx]\n",
    "        y_test = [y[i] for i in test_idx]\n",
    "        normalizer = Normalizer().fit(X_train)\n",
    "        X_train = normalizer.transform(X_train)\n",
    "        X_test = normalizer.transform(X_test)\n",
    "    clf = svm.SVC(C=100.0, kernel='poly', degree=6, gamma='scale', \n",
    "              coef0=0.0, shrinking=True, probability=False, tol=0.001, \n",
    "              cache_size=200, class_weight=None, verbose=False, max_iter=-1, \n",
    "              decision_function_shape='ovr', random_state=None)\n",
    "    clf.fit(X_train, y_train)  \n",
    "    print(\"Train: \", f1_score(y_pred=clf.predict(X_train), y_true=y_train, average='micro'))\n",
    "    print(\"Test: \", f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='micro'))\n",
    "    test_avg.append(f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='micro'))\n",
    "print(\"Final avg: \", sum(test_avg)/10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (E2) GIN split with neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc:  0.632258064516129\n",
      "Test acc:  0.5882352941176471\n",
      "Train f1m:  0.5674418604651162\n",
      "Test f1m:  0.5041666666666667\n",
      "Train acc:  0.6645161290322581\n",
      "Test acc:  0.7058823529411765\n",
      "Train f1m:  0.6305463879721306\n",
      "Test f1m:  0.6458333333333334\n",
      "Train acc:  0.6516129032258065\n",
      "Test acc:  0.6764705882352942\n",
      "Train f1m:  0.6054864253393666\n",
      "Test f1m:  0.6693191865605659\n",
      "Train acc:  0.6774193548387096\n",
      "Test acc:  0.5\n",
      "Train f1m:  0.6518575086474103\n",
      "Test f1m:  0.48894783377541995\n",
      "Train acc:  0.6741935483870968\n",
      "Test acc:  0.6176470588235294\n",
      "Train f1m:  0.6388321740434417\n",
      "Test f1m:  0.5252416756176155\n",
      "Train acc:  0.632258064516129\n",
      "Test acc:  0.5294117647058824\n",
      "Train f1m:  0.5674418604651164\n",
      "Test f1m:  0.39555555555555555\n",
      "Train acc:  0.6741935483870968\n",
      "Test acc:  0.5294117647058824\n",
      "Train f1m:  0.6515652299713997\n",
      "Test f1m:  0.5277777777777778\n",
      "Train acc:  0.6483870967741936\n",
      "Test acc:  0.6470588235294118\n",
      "Train f1m:  0.6378000021438295\n",
      "Test f1m:  0.6458333333333333\n",
      "Train acc:  0.6709677419354839\n",
      "Test acc:  0.5588235294117647\n",
      "Train f1m:  0.6435335497835498\n",
      "Test f1m:  0.45220193340494097\n",
      "Train acc:  0.6516129032258065\n",
      "Test acc:  0.5\n",
      "Train f1m:  0.6462981744421907\n",
      "Test f1m:  0.4960767218831734\n",
      "Final avg:  0.5852941176470589\n",
      "CPU times: user 43.9 s, sys: 863 ms, total: 44.7 s\n",
      "Wall time: 7.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Report accuracies\n",
    "test_avg = []\n",
    "for i in range (1,11):\n",
    "    with open(\"../data/PTC/10fold_idx/test_idx-{}.txt\".format(i), \"r\") as test_f,\\\n",
    "         open(\"../data/PTC/10fold_idx/train_idx-{}.txt\".format(i), \"r\") as train_f:\n",
    "        train_idx = [int(i) for i in train_f.readlines()]\n",
    "        test_idx = [int(i) for i in test_f.readlines()]\n",
    "        X_train = [X[i] for i in train_idx]\n",
    "        X_test = [X[i] for i in test_idx]\n",
    "        y_train = [y[i] for i in train_idx]\n",
    "        y_test = [y[i] for i in test_idx]\n",
    "        normalizer = Normalizer().fit(X_train)\n",
    "        X_train = normalizer.transform(X_train)\n",
    "        X_test = normalizer.transform(X_test)\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(128,64), activation='relu', \n",
    "                        solver='adam', alpha=0.001, batch_size=16, \n",
    "                        learning_rate='adaptive', learning_rate_init=0.01, \n",
    "                        power_t=0.5, max_iter=500, shuffle=True, \n",
    "                        random_state=None, tol=0.0001, verbose=False, \n",
    "                        warm_start=False, momentum=0.9, \n",
    "                        nesterovs_momentum=True, early_stopping=False, \n",
    "                        validation_fraction=0.1, beta_1=0.9, beta_2=0.999, \n",
    "                        epsilon=1e-08, n_iter_no_change=10)\n",
    "    clf.fit(X_train, y_train)  \n",
    "    print(\"Train acc: \", accuracy_score(y_pred=clf.predict(X_train), y_true=y_train))\n",
    "    print(\"Test acc: \", accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "    print(\"Train f1m: \", f1_score(y_pred=clf.predict(X_train), y_true=y_train, average='macro'))\n",
    "    print(\"Test f1m: \", f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro'))\n",
    "    test_avg.append(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(\"Final avg: \", sum(test_avg)/10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (E3) Ensemble model (adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc:  0.6903225806451613\n",
      "Test acc:  0.6470588235294118\n",
      "Train f1m:  0.6726648774693124\n",
      "Test f1m:  0.6263736263736264\n",
      "Train acc:  0.7129032258064516\n",
      "Test acc:  0.7352941176470589\n",
      "Train f1m:  0.6883577503925178\n",
      "Test f1m:  0.6713211600429645\n",
      "Train acc:  0.7387096774193549\n",
      "Test acc:  0.5882352941176471\n",
      "Train f1m:  0.7259062776304156\n",
      "Test f1m:  0.5882352941176471\n",
      "Train acc:  0.7387096774193549\n",
      "Test acc:  0.5\n",
      "Train f1m:  0.7205622141354788\n",
      "Test f1m:  0.48894783377541995\n",
      "Train acc:  0.7516129032258064\n",
      "Test acc:  0.6470588235294118\n",
      "Train f1m:  0.744703151905368\n",
      "Test f1m:  0.6136363636363635\n",
      "Train acc:  0.7516129032258064\n",
      "Test acc:  0.6470588235294118\n",
      "Train f1m:  0.7394417700931111\n",
      "Test f1m:  0.5968379446640317\n",
      "Train acc:  0.7258064516129032\n",
      "Test acc:  0.5294117647058824\n",
      "Train f1m:  0.7131972789115646\n",
      "Test f1m:  0.5294117647058824\n",
      "Train acc:  0.7161290322580646\n",
      "Test acc:  0.6176470588235294\n",
      "Train f1m:  0.6958751393534002\n",
      "Test f1m:  0.5888372093023256\n",
      "Train acc:  0.7548387096774194\n",
      "Test acc:  0.5294117647058824\n",
      "Train f1m:  0.7471668956043958\n",
      "Test f1m:  0.5018315018315018\n",
      "Train acc:  0.7354838709677419\n",
      "Test acc:  0.6176470588235294\n",
      "Train f1m:  0.7229246599232648\n",
      "Test f1m:  0.6091954022988506\n",
      "Final avg:  0.6058823529411764\n",
      "CPU times: user 6.06 s, sys: 140 µs, total: 6.06 s\n",
      "Wall time: 6.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Report accuracies\n",
    "test_avg = []\n",
    "for i in range (1,11):\n",
    "    with open(\"../data/PTC/10fold_idx/test_idx-{}.txt\".format(i), \"r\") as test_f,\\\n",
    "         open(\"../data/PTC/10fold_idx/train_idx-{}.txt\".format(i), \"r\") as train_f:\n",
    "        train_idx = [int(i) for i in train_f.readlines()]\n",
    "        test_idx = [int(i) for i in test_f.readlines()]\n",
    "        X_train = [X[i] for i in train_idx]\n",
    "        X_test = [X[i] for i in test_idx]\n",
    "        y_train = [y[i] for i in train_idx]\n",
    "        y_test = [y[i] for i in test_idx]\n",
    "        normalizer = Normalizer().fit(X_train)\n",
    "        X_train = normalizer.transform(X_train)\n",
    "        X_test = normalizer.transform(X_test)\n",
    "    clf = AdaBoostClassifier(base_estimator=svm.SVC(C=1000.0, kernel='rbf', degree=3, gamma=4.0, \n",
    "              coef0=0.0, shrinking=True, probability=False, tol=0.001, \n",
    "              cache_size=200, class_weight=None, verbose=False, max_iter=-1, \n",
    "              decision_function_shape='ovr', random_state=None), n_estimators=50, \n",
    "                             learning_rate=1.0, algorithm='SAMME', random_state=None)\n",
    "    clf.fit(X_train, y_train)  \n",
    "    print(\"Train acc: \", accuracy_score(y_pred=clf.predict(X_train), y_true=y_train))\n",
    "    print(\"Test acc: \", accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "    print(\"Train f1m: \", f1_score(y_pred=clf.predict(X_train), y_true=y_train, average='macro'))\n",
    "    print(\"Test f1m: \", f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro'))\n",
    "    test_avg.append(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(\"Final avg: \", sum(test_avg)/10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (E3) Uses features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [list(sum(g.node_features).numpy()) for g in ptc_graphs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf = copy.deepcopy(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X)):\n",
    "    Xf[i].extend(features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final avg:  0.65 0.0713803594088918\n",
      "CPU times: user 133 ms, sys: 0 ns, total: 133 ms\n",
      "Wall time: 132 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_avg = []\n",
    "for i in range (1,11):\n",
    "    with open(\"../data/PTC/10fold_idx/test_idx-{}.txt\".format(i), \"r\") as test_f,\\\n",
    "         open(\"../data/PTC/10fold_idx/train_idx-{}.txt\".format(i), \"r\") as train_f:\n",
    "        train_idx = [int(i) for i in train_f.readlines()]\n",
    "        test_idx = [int(i) for i in test_f.readlines()]\n",
    "        X_train = [Xf[i] for i in train_idx]\n",
    "        X_test = [Xf[i] for i in test_idx]\n",
    "        y_train = [y[i] for i in train_idx]\n",
    "        y_test = [y[i] for i in test_idx]\n",
    "        normalizer = Normalizer().fit(X_train)\n",
    "        X_train = normalizer.transform(X_train)\n",
    "        X_test = normalizer.transform(X_test)\n",
    "    clf = svm.SVC(C=100.0, kernel='poly', degree=4, gamma='scale', \n",
    "              coef0=0.0, shrinking=True, probability=False, tol=0.001, \n",
    "              cache_size=200, class_weight=None, verbose=False, max_iter=-1, \n",
    "              decision_function_shape='ovr', random_state=None)\n",
    "    clf.fit(X_train, y_train)  \n",
    "    #print(\"Train: \", f1_score(y_pred=clf.predict(X_train), y_true=y_train, average='micro'))\n",
    "    #print(\"Test: \", f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='micro'))\n",
    "    test_avg.append(f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='micro'))\n",
    "print(\"Final avg: \", np.mean(test_avg), np.std(test_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final avg:  0.6352941176470589 0.06197443384031026\n",
      "CPU times: user 115 ms, sys: 32 µs, total: 115 ms\n",
      "Wall time: 114 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_avg = []\n",
    "for i in range (1,11):\n",
    "    with open(\"../data/PTC/10fold_idx/test_idx-{}.txt\".format(i), \"r\") as test_f,\\\n",
    "         open(\"../data/PTC/10fold_idx/train_idx-{}.txt\".format(i), \"r\") as train_f:\n",
    "        train_idx = [int(i) for i in train_f.readlines()]\n",
    "        test_idx = [int(i) for i in test_f.readlines()]\n",
    "        X_train = [Xf[i] for i in train_idx]\n",
    "        X_test = [Xf[i] for i in test_idx]\n",
    "        y_train = [y[i] for i in train_idx]\n",
    "        y_test = [y[i] for i in test_idx]\n",
    "        normalizer = Normalizer().fit(X_train)\n",
    "        X_train = normalizer.transform(X_train)\n",
    "        X_test = normalizer.transform(X_test)\n",
    "    clf = svm.SVC(C=400.0, kernel='rbf', degree=4, gamma=1.0, \n",
    "              coef0=0.0, shrinking=True, probability=False, tol=0.001, \n",
    "              cache_size=200, class_weight=None, verbose=False, max_iter=-1, \n",
    "              decision_function_shape='ovr', random_state=None)\n",
    "    clf.fit(X_train, y_train)  \n",
    "    #print(\"Train: \", f1_score(y_pred=clf.predict(X_train), y_true=y_train, average='micro'))\n",
    "    #print(\"Test: \", f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='micro'))\n",
    "    test_avg.append(f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='micro'))\n",
    "print(\"Final avg: \", np.mean(test_avg), np.std(test_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
