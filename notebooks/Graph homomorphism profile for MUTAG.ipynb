{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data, nx2gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_tool.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load graphs (MUTAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "# classes: 2\n",
      "# maximum node tag: 7\n",
      "# data: 188\n"
     ]
    }
   ],
   "source": [
    "mutag_graphs = load_data(\"MUTAG\", degree_as_tag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for i in nx.generators.nonisomorphic_trees(4):\n",
    "    print(i.is_directed())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test counting trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_g = nx2gt(mutag_graphs[0][0].g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_4 = [nx2gt(f) for f in nx.generators.nonisomorphic_trees(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 994 µs, sys: 0 ns, total: 994 µs\n",
      "Wall time: 997 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<Graph object, undirected, with 4 vertices and 3 edges at 0x7f6a9b7d9b38>,\n",
       "  <Graph object, undirected, with 4 vertices and 3 edges at 0x7f6a9b7d9a58>],\n",
       " [10, 63])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "motifs(g=test_g, k=4, p=1.0, motif_list=trees_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_6 = [nx2gt(f) for f in nx.generators.nonisomorphic_trees(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.86 ms, sys: 0 ns, total: 1.86 ms\n",
      "Wall time: 1.87 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<Graph object, undirected, with 6 vertices and 5 edges at 0x7f6a9b7f5400>,\n",
       "  <Graph object, undirected, with 6 vertices and 5 edges at 0x7f6a9b7f52b0>,\n",
       "  <Graph object, undirected, with 6 vertices and 5 edges at 0x7f6a9b7effd0>,\n",
       "  <Graph object, undirected, with 6 vertices and 5 edges at 0x7f6a9b7efe80>,\n",
       "  <Graph object, undirected, with 6 vertices and 5 edges at 0x7f6a9b7f5160>,\n",
       "  <Graph object, undirected, with 6 vertices and 5 edges at 0x7f6a9b7efda0>],\n",
       " [0, 0, 10, 70, 77, 113])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "motifs(g=test_g, k=6, p=1.0, motif_list=trees_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_2 = [nx2gt(f) for f in nx.generators.nonisomorphic_trees(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 295 µs, sys: 18 µs, total: 313 µs\n",
      "Wall time: 315 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<Graph object, undirected, with 2 vertices and 1 edge at 0x7f6a9b7f56d8>],\n",
       " [27])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "motifs(g=test_g, k=2, p=1.0, motif_list=trees_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutag_graphs[0][0].label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run homomorphism profile for MUTAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_2 = [nx2gt(f) for f in nx.generators.nonisomorphic_trees(2)]\n",
    "trees_3 = [nx2gt(f) for f in nx.generators.nonisomorphic_trees(3)]\n",
    "trees_4 = [nx2gt(f) for f in nx.generators.nonisomorphic_trees(4)]\n",
    "trees_5 = [nx2gt(f) for f in nx.generators.nonisomorphic_trees(5)]\n",
    "trees_6 = [nx2gt(f) for f in nx.generators.nonisomorphic_trees(6)]\n",
    "trees_7 = [nx2gt(f) for f in nx.generators.nonisomorphic_trees(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trees = [trees_2, trees_3, trees_4, trees_5, trees_6, trees_7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 978 ms, sys: 313 µs, total: 978 ms\n",
      "Wall time: 978 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = []\n",
    "y = []\n",
    "for g in mutag_graphs[0]:\n",
    "    gt = nx2gt(g.g)\n",
    "    profile = []\n",
    "    for i, trees in enumerate(all_trees):\n",
    "        profile.extend(motifs(g=gt, k=i+2, p=1.0, motif_list=trees)[1])\n",
    "    X.append(profile)\n",
    "    y.append(g.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test simple ML approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = normalizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = normalizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (E1) Default SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.52 ms, sys: 107 µs, total: 2.63 ms\n",
      "Wall time: 1.59 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.853932584269663\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", f1_score(y_pred=clf.predict(X_train), y_true=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  0.8095238095238095\n"
     ]
    }
   ],
   "source": [
    "print(\"Test: \", f1_score(y_pred=clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (E2) Tune SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.1 ms, sys: 148 µs, total: 2.25 ms\n",
      "Wall time: 1.48 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = svm.SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', \n",
    "              coef0=0.0, shrinking=True, probability=False, tol=0.001, \n",
    "              cache_size=200, class_weight=None, verbose=False, max_iter=-1, \n",
    "              decision_function_shape='ovr', random_state=None)\n",
    "clf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.8960000000000001\n",
      "Test:  0.8730158730158731\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", f1_score(y_pred=clf.predict(X_train), y_true=y_train, average='micro'))\n",
    "print(\"Test: \", f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (E3) Setup MUTAG as 18 graphs for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer().fit(X_train)\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.34 ms, sys: 0 ns, total: 3.34 ms\n",
      "Wall time: 2.55 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = svm.SVC(C=1000.0, kernel='rbf', degree=6, gamma='scale', \n",
    "              coef0=0.0, shrinking=True, probability=False, tol=0.001, \n",
    "              cache_size=200, class_weight=None, verbose=False, max_iter=-1, \n",
    "              decision_function_shape='ovr', random_state=None)\n",
    "clf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.9230769230769231\n",
      "Test:  0.7894736842105263\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", f1_score(y_pred=clf.predict(X_train), y_true=y_train, average='micro'))\n",
    "print(\"Test: \", f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.9763313609467456\n",
      "Test:  0.7894736842105263\n",
      "CPU times: user 28.5 ms, sys: 2.99 ms, total: 31.5 ms\n",
      "Wall time: 28.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = svm.SVC(C=1000.0, kernel='poly', degree=6, gamma='scale', \n",
    "              coef0=0.0, shrinking=True, probability=False, tol=0.001, \n",
    "              cache_size=200, class_weight=None, verbose=False, max_iter=-1, \n",
    "              decision_function_shape='ovr', random_state=None)\n",
    "clf.fit(X_train, y_train)  \n",
    "\n",
    "print(\"Train: \", f1_score(y_pred=clf.predict(X_train), y_true=y_train, average='micro'))\n",
    "print(\"Test: \", f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (E4) Use GIN splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.96040987424313\n",
      "Test:  0.625\n",
      "Train:  0.9616483681756656\n",
      "Test:  0.9113300492610837\n",
      "Train:  0.9610627576729273\n",
      "Test:  0.925925925925926\n",
      "Train:  0.9736065828287533\n",
      "Test:  0.7749999999999999\n",
      "Train:  0.974041838448618\n",
      "Test:  0.8036363636363635\n",
      "Train:  0.9671497584541062\n",
      "Test:  0.7662337662337663\n",
      "Train:  0.9668628903356593\n",
      "Test:  0.8193979933110367\n",
      "Train:  0.9671497584541062\n",
      "Test:  0.8193979933110367\n",
      "Train:  0.9665604469097918\n",
      "Test:  0.888888888888889\n",
      "Train:  0.9613636363636364\n",
      "Test:  0.8392857142857143\n",
      "Final avg:  0.8174096694853816\n",
      "CPU times: user 114 ms, sys: 10.2 ms, total: 124 ms\n",
      "Wall time: 121 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_avg = []\n",
    "for i in range (1,11):\n",
    "    with open(\"../data/MUTAG/10fold_idx/test_idx-{}.txt\".format(i), \"r\") as test_f,\\\n",
    "         open(\"../data/MUTAG/10fold_idx/train_idx-{}.txt\".format(i), \"r\") as train_f:\n",
    "        train_idx = [int(i) for i in train_f.readlines()]\n",
    "        test_idx = [int(i) for i in test_f.readlines()]\n",
    "        X_train = [X[i] for i in train_idx]\n",
    "        X_test = [X[i] for i in test_idx]\n",
    "        y_train = [y[i] for i in train_idx]\n",
    "        y_test = [y[i] for i in test_idx]\n",
    "        normalizer = Normalizer().fit(X_train)\n",
    "        X_train = normalizer.transform(X_train)\n",
    "        X_test = normalizer.transform(X_test)\n",
    "    clf = svm.SVC(C=1000.0, kernel='poly', degree=6, gamma='scale', \n",
    "              coef0=0.0, shrinking=True, probability=False, tol=0.001, \n",
    "              cache_size=200, class_weight=None, verbose=False, max_iter=-1, \n",
    "              decision_function_shape='ovr', random_state=None)\n",
    "    clf.fit(X_train, y_train)  \n",
    "    print(\"Train: \", f1_score(y_pred=clf.predict(X_train), y_true=y_train, average='macro'))\n",
    "    print(\"Test: \", f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro'))\n",
    "    test_avg.append(f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro'))\n",
    "print(\"Final avg: \", sum(test_avg)/10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.9235294117647059\n",
      "Test:  0.7777777777777778\n",
      "Train:  0.9176470588235294\n",
      "Test:  0.9444444444444444\n",
      "Train:  0.9058823529411765\n",
      "Test:  1.0\n",
      "Train:  0.9235294117647059\n",
      "Test:  0.8333333333333334\n",
      "Train:  0.9235294117647059\n",
      "Test:  0.7777777777777778\n",
      "Train:  0.9235294117647059\n",
      "Test:  0.7777777777777778\n",
      "Train:  0.9176470588235294\n",
      "Test:  0.8333333333333334\n",
      "Train:  0.9235294117647059\n",
      "Test:  0.8333333333333334\n",
      "Train:  0.9058823529411765\n",
      "Test:  0.9444444444444444\n",
      "Train:  0.9117647058823529\n",
      "Test:  1.0\n",
      "Final avg:  0.8722222222222221\n",
      "CPU times: user 38.1 ms, sys: 48 µs, total: 38.1 ms\n",
      "Wall time: 34.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Report accuracies\n",
    "test_avg = []\n",
    "for i in range (1,11):\n",
    "    with open(\"../data/MUTAG/10fold_idx/test_idx-{}.txt\".format(i), \"r\") as test_f,\\\n",
    "         open(\"../data/MUTAG/10fold_idx/train_idx-{}.txt\".format(i), \"r\") as train_f:\n",
    "        train_idx = [int(i) for i in train_f.readlines()]\n",
    "        test_idx = [int(i) for i in test_f.readlines()]\n",
    "        X_train = [X[i] for i in train_idx]\n",
    "        X_test = [X[i] for i in test_idx]\n",
    "        y_train = [y[i] for i in train_idx]\n",
    "        y_test = [y[i] for i in test_idx]\n",
    "        normalizer = Normalizer().fit(X_train)\n",
    "        X_train = normalizer.transform(X_train)\n",
    "        X_test = normalizer.transform(X_test)\n",
    "    clf = svm.SVC(C=100.0, kernel='poly', degree=3, gamma='scale', \n",
    "              coef0=0.0, shrinking=True, probability=False, tol=0.001, \n",
    "              cache_size=200, class_weight=None, verbose=False, max_iter=-1, \n",
    "              decision_function_shape='ovr', random_state=None)\n",
    "    clf.fit(X_train, y_train)  \n",
    "    print(\"Train: \", accuracy_score(y_pred=clf.predict(X_train), y_true=y_train))\n",
    "    print(\"Test: \", accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "    test_avg.append(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(\"Final avg: \", sum(test_avg)/10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08624541497922233"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(test_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (E5) More trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_8 = [nx2gt(f) for f in nx.generators.nonisomorphic_trees(8)]\n",
    "trees_9 = [nx2gt(f) for f in nx.generators.nonisomorphic_trees(9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trees = [trees_2, trees_3, trees_4, trees_5, trees_6, trees_7, trees_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.86 s, sys: 2.03 ms, total: 1.86 s\n",
      "Wall time: 1.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = []\n",
    "y = []\n",
    "for g in mutag_graphs[0]:\n",
    "    gt = nx2gt(g.g)\n",
    "    profile = []\n",
    "    for i, trees in enumerate(all_trees):\n",
    "        profile.extend(motifs(g=gt, k=i+2, p=1.0, motif_list=trees)[1])\n",
    "    X.append(profile)\n",
    "    y.append(g.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc:  0.9529411764705882\n",
      "Test acc:  0.7777777777777778\n",
      "Train f1m:  0.9472131656575065\n",
      "Test f1m:  0.75\n",
      "Train acc:  0.9588235294117647\n",
      "Test acc:  0.9444444444444444\n",
      "Train f1m:  0.95541568318909\n",
      "Test f1m:  0.9113300492610837\n",
      "Train acc:  0.9647058823529412\n",
      "Test acc:  0.8888888888888888\n",
      "Train f1m:  0.9610627576729273\n",
      "Test f1m:  0.8392857142857142\n",
      "Train acc:  0.9764705882352941\n",
      "Test acc:  0.8333333333333334\n",
      "Train f1m:  0.9736065828287533\n",
      "Test f1m:  0.8285714285714285\n",
      "Train acc:  0.9647058823529412\n",
      "Test acc:  0.7777777777777778\n",
      "Train f1m:  0.9610627576729273\n",
      "Test f1m:  0.7230769230769231\n",
      "Train acc:  0.9588235294117647\n",
      "Test acc:  0.8333333333333334\n",
      "Train f1m:  0.9540096618357488\n",
      "Test f1m:  0.8193979933110367\n",
      "Train acc:  0.9705882352941176\n",
      "Test acc:  0.8888888888888888\n",
      "Train f1m:  0.9668628903356593\n",
      "Test f1m:  0.8831168831168831\n",
      "Train acc:  0.9705882352941176\n",
      "Test acc:  0.7777777777777778\n",
      "Train f1m:  0.9671497584541062\n",
      "Test f1m:  0.7662337662337663\n",
      "Train acc:  0.9647058823529412\n",
      "Test acc:  0.8888888888888888\n",
      "Train f1m:  0.9596837944664032\n",
      "Test f1m:  0.888888888888889\n",
      "Train acc:  0.9588235294117647\n",
      "Test acc:  1.0\n",
      "Train f1m:  0.955092645005472\n",
      "Test f1m:  1.0\n",
      "Final avg:  0.861111111111111\n"
     ]
    }
   ],
   "source": [
    "# Report accuracies\n",
    "test_avg = []\n",
    "for i in range (1,11):\n",
    "    with open(\"../data/MUTAG/10fold_idx/test_idx-{}.txt\".format(i), \"r\") as test_f,\\\n",
    "         open(\"../data/MUTAG/10fold_idx/train_idx-{}.txt\".format(i), \"r\") as train_f:\n",
    "        train_idx = [int(i) for i in train_f.readlines()]\n",
    "        test_idx = [int(i) for i in test_f.readlines()]\n",
    "        X_train = [X[i] for i in train_idx]\n",
    "        X_test = [X[i] for i in test_idx]\n",
    "        y_train = [y[i] for i in train_idx]\n",
    "        y_test = [y[i] for i in test_idx]\n",
    "        normalizer = Normalizer().fit(X_train)\n",
    "        X_train = normalizer.transform(X_train)\n",
    "        X_test = normalizer.transform(X_test)\n",
    "    clf = svm.SVC(C=1000.0, kernel='rbf', degree=3, gamma='scale', \n",
    "              coef0=0.0, shrinking=True, probability=False, tol=0.001, \n",
    "              cache_size=200, class_weight=None, verbose=False, max_iter=-1, \n",
    "              decision_function_shape='ovr', random_state=None)\n",
    "    clf.fit(X_train, y_train)  \n",
    "    print(\"Train acc: \", accuracy_score(y_pred=clf.predict(X_train), y_true=y_train))\n",
    "    print(\"Test acc: \", accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "    print(\"Train f1m: \", f1_score(y_pred=clf.predict(X_train), y_true=y_train, average='macro'))\n",
    "    print(\"Test f1m: \", f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro'))\n",
    "    test_avg.append(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(\"Final avg: \", sum(test_avg)/10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (E6) Gaussian Process as classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc:  0.7705882352941177\n",
      "Test acc:  0.5\n",
      "Train f1m:  0.703209633376606\n",
      "Test f1m:  0.3333333333333333\n",
      "Train acc:  0.7352941176470589\n",
      "Test acc:  0.8888888888888888\n",
      "Train f1m:  0.6669713987201253\n",
      "Test f1m:  0.8\n",
      "Train acc:  0.7411764705882353\n",
      "Test acc:  0.8333333333333334\n",
      "Train f1m:  0.6721598877980365\n",
      "Test f1m:  0.7339901477832513\n",
      "Train acc:  0.7588235294117647\n",
      "Test acc:  0.6111111111111112\n",
      "Train f1m:  0.6833401481077643\n",
      "Test f1m:  0.5418181818181819\n",
      "Train acc:  0.7529411764705882\n",
      "Test acc:  0.7222222222222222\n",
      "Train f1m:  0.6826666666666668\n",
      "Test f1m:  0.6296296296296297\n",
      "Train acc:  0.7411764705882353\n",
      "Test acc:  0.7777777777777778\n",
      "Train f1m:  0.6626984126984127\n",
      "Test f1m:  0.723076923076923\n",
      "Train acc:  0.7352941176470589\n",
      "Test acc:  0.8333333333333334\n",
      "Train f1m:  0.6470588235294117\n",
      "Test f1m:  0.8193979933110367\n",
      "Train acc:  0.7470588235294118\n",
      "Test acc:  0.7222222222222222\n",
      "Train f1m:  0.6727695957742066\n",
      "Test f1m:  0.6296296296296295\n",
      "Train acc:  0.7588235294117647\n",
      "Test acc:  0.6111111111111112\n",
      "Train f1m:  0.6833401481077643\n",
      "Test f1m:  0.5418181818181819\n",
      "Train acc:  0.7294117647058823\n",
      "Test acc:  0.9444444444444444\n",
      "Train f1m:  0.657258064516129\n",
      "Test f1m:  0.9113300492610837\n",
      "Final avg:  0.7444444444444445\n",
      "CPU times: user 638 ms, sys: 20.2 ms, total: 658 ms\n",
      "Wall time: 112 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Report accuracies\n",
    "test_avg = []\n",
    "for i in range (1,11):\n",
    "    with open(\"../data/MUTAG/10fold_idx/test_idx-{}.txt\".format(i), \"r\") as test_f,\\\n",
    "         open(\"../data/MUTAG/10fold_idx/train_idx-{}.txt\".format(i), \"r\") as train_f:\n",
    "        train_idx = [int(i) for i in train_f.readlines()]\n",
    "        test_idx = [int(i) for i in test_f.readlines()]\n",
    "        X_train = [X[i] for i in train_idx]\n",
    "        X_test = [X[i] for i in test_idx]\n",
    "        y_train = [y[i] for i in train_idx]\n",
    "        y_test = [y[i] for i in test_idx]\n",
    "        normalizer = Normalizer().fit(X_train)\n",
    "        X_train = normalizer.transform(X_train)\n",
    "        X_test = normalizer.transform(X_test)\n",
    "    clf = GaussianProcessClassifier(kernel=None, optimizer='fmin_l_bfgs_b', \n",
    "                                n_restarts_optimizer=0, max_iter_predict=200, \n",
    "                                warm_start=False, copy_X_train=True, \n",
    "                                random_state=42, multi_class='one_vs_rest', \n",
    "                                n_jobs=4)\n",
    "    clf.fit(X_train, y_train)  \n",
    "    print(\"Train acc: \", accuracy_score(y_pred=clf.predict(X_train), y_true=y_train))\n",
    "    print(\"Test acc: \", accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "    print(\"Train f1m: \", f1_score(y_pred=clf.predict(X_train), y_true=y_train, average='macro'))\n",
    "    print(\"Test f1m: \", f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro'))\n",
    "    test_avg.append(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(\"Final avg: \", sum(test_avg)/10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (E7) MLP as classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc:  0.8941176470588236\n",
      "Test acc:  0.7777777777777778\n",
      "Train f1m:  0.8822352216748769\n",
      "Test f1m:  0.7662337662337663\n",
      "Train acc:  0.8588235294117647\n",
      "Test acc:  0.9444444444444444\n",
      "Train f1m:  0.8454545454545455\n",
      "Test f1m:  0.9113300492610837\n",
      "Train acc:  0.8705882352941177\n",
      "Test acc:  1.0\n",
      "Train f1m:  0.8572301114673996\n",
      "Test f1m:  1.0\n",
      "Train acc:  0.8764705882352941\n",
      "Test acc:  0.8888888888888888\n",
      "Train f1m:  0.8582151793160968\n",
      "Test f1m:  0.8875000000000001\n",
      "Train acc:  0.8823529411764706\n",
      "Test acc:  0.7222222222222222\n",
      "Train f1m:  0.8691502463054187\n",
      "Test f1m:  0.6296296296296297\n",
      "Train acc:  0.8823529411764706\n",
      "Test acc:  0.8333333333333334\n",
      "Train f1m:  0.8680329141437664\n",
      "Test f1m:  0.8193979933110367\n",
      "Train acc:  0.8764705882352941\n",
      "Test acc:  0.8333333333333334\n",
      "Train f1m:  0.859553877021126\n",
      "Test f1m:  0.8193979933110367\n",
      "Train acc:  0.8941176470588236\n",
      "Test acc:  0.7777777777777778\n",
      "Train f1m:  0.8822352216748768\n",
      "Test f1m:  0.75\n",
      "Train acc:  0.8823529411764706\n",
      "Test acc:  0.8888888888888888\n",
      "Train f1m:  0.8668546365914787\n",
      "Test f1m:  0.8875\n",
      "Train acc:  0.8588235294117647\n",
      "Test acc:  0.9444444444444444\n",
      "Train f1m:  0.8429802955665024\n",
      "Test f1m:  0.925925925925926\n",
      "Final avg:  0.861111111111111\n",
      "CPU times: user 31.5 s, sys: 623 ms, total: 32.2 s\n",
      "Wall time: 5.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Report accuracies\n",
    "test_avg = []\n",
    "for i in range (1,11):\n",
    "    with open(\"../data/MUTAG/10fold_idx/test_idx-{}.txt\".format(i), \"r\") as test_f,\\\n",
    "         open(\"../data/MUTAG/10fold_idx/train_idx-{}.txt\".format(i), \"r\") as train_f:\n",
    "        train_idx = [int(i) for i in train_f.readlines()]\n",
    "        test_idx = [int(i) for i in test_f.readlines()]\n",
    "        X_train = [X[i] for i in train_idx]\n",
    "        X_test = [X[i] for i in test_idx]\n",
    "        y_train = [y[i] for i in train_idx]\n",
    "        y_test = [y[i] for i in test_idx]\n",
    "        normalizer = Normalizer().fit(X_train)\n",
    "        X_train = normalizer.transform(X_train)\n",
    "        X_test = normalizer.transform(X_test)\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(200,), activation='relu', \n",
    "                        solver='adam', alpha=0.00001, batch_size=16, \n",
    "                        learning_rate='adaptive', learning_rate_init=0.001, \n",
    "                        power_t=0.5, max_iter=500, shuffle=True, \n",
    "                        random_state=None, tol=0.0001, verbose=False, \n",
    "                        warm_start=False, momentum=0.9, \n",
    "                        nesterovs_momentum=True, early_stopping=False, \n",
    "                        validation_fraction=0.1, beta_1=0.9, beta_2=0.999, \n",
    "                        epsilon=1e-08, n_iter_no_change=10)\n",
    "    clf.fit(X_train, y_train)  \n",
    "    print(\"Train acc: \", accuracy_score(y_pred=clf.predict(X_train), y_true=y_train))\n",
    "    print(\"Test acc: \", accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "    print(\"Train f1m: \", f1_score(y_pred=clf.predict(X_train), y_true=y_train, average='macro'))\n",
    "    print(\"Test f1m: \", f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro'))\n",
    "    test_avg.append(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(\"Final avg: \", sum(test_avg)/10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (E8) Preprocess with StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc:  0.9411764705882353\n",
      "Test acc:  0.7777777777777778\n",
      "Train f1m:  0.9356060606060606\n",
      "Test f1m:  0.7662337662337663\n",
      "Train acc:  0.9235294117647059\n",
      "Test acc:  0.8888888888888888\n",
      "Train f1m:  0.9177674418604652\n",
      "Test f1m:  0.8392857142857142\n",
      "Train acc:  0.9352941176470588\n",
      "Test acc:  1.0\n",
      "Train f1m:  0.9299389307257127\n",
      "Test f1m:  1.0\n",
      "Train acc:  0.9294117647058824\n",
      "Test acc:  0.8888888888888888\n",
      "Train f1m:  0.9214901477832513\n",
      "Test f1m:  0.8875000000000001\n",
      "Train acc:  0.9352941176470588\n",
      "Test acc:  0.8333333333333334\n",
      "Train f1m:  0.9304186046511629\n",
      "Test f1m:  0.8036363636363635\n",
      "Train acc:  0.9294117647058824\n",
      "Test acc:  0.8888888888888888\n",
      "Train f1m:  0.9227272727272726\n",
      "Test f1m:  0.8831168831168831\n",
      "Train acc:  0.9411764705882353\n",
      "Test acc:  0.8333333333333334\n",
      "Train f1m:  0.9351045961215453\n",
      "Test f1m:  0.8193979933110367\n",
      "Train acc:  0.9352941176470588\n",
      "Test acc:  0.7777777777777778\n",
      "Train f1m:  0.929431299294313\n",
      "Test f1m:  0.7662337662337663\n",
      "Train acc:  0.9294117647058824\n",
      "Test acc:  0.8333333333333334\n",
      "Train f1m:  0.9227272727272726\n",
      "Test f1m:  0.8328173374613004\n",
      "Train acc:  0.9294117647058824\n",
      "Test acc:  1.0\n",
      "Train f1m:  0.9248231132075471\n",
      "Test f1m:  1.0\n",
      "Final avg:  0.8722222222222221\n",
      "CPU times: user 16.1 s, sys: 173 ms, total: 16.3 s\n",
      "Wall time: 7.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Report accuracies\n",
    "test_avg = []\n",
    "for i in range (1,11):\n",
    "    with open(\"../data/MUTAG/10fold_idx/test_idx-{}.txt\".format(i), \"r\") as test_f,\\\n",
    "         open(\"../data/MUTAG/10fold_idx/train_idx-{}.txt\".format(i), \"r\") as train_f:\n",
    "        train_idx = [int(i) for i in train_f.readlines()]\n",
    "        test_idx = [int(i) for i in test_f.readlines()]\n",
    "        X_train = [X[i] for i in train_idx]\n",
    "        X_test = [X[i] for i in test_idx]\n",
    "        y_train = [y[i] for i in train_idx]\n",
    "        y_test = [y[i] for i in test_idx]\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(64,32), activation='relu', \n",
    "                        solver='adam', alpha=0.001, batch_size=16, \n",
    "                        learning_rate='adaptive', learning_rate_init=0.001, \n",
    "                        power_t=0.5, max_iter=500, shuffle=True, \n",
    "                        random_state=None, tol=0.0001, verbose=False, \n",
    "                        warm_start=False, momentum=0.9, \n",
    "                        nesterovs_momentum=True, early_stopping=False, \n",
    "                        validation_fraction=0.1, beta_1=0.9, beta_2=0.999, \n",
    "                        epsilon=1e-08, n_iter_no_change=10)\n",
    "    clf.fit(X_train, y_train)  \n",
    "    print(\"Train acc: \", accuracy_score(y_pred=clf.predict(X_train), y_true=y_train))\n",
    "    print(\"Test acc: \", accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "    print(\"Train f1m: \", f1_score(y_pred=clf.predict(X_train), y_true=y_train, average='macro'))\n",
    "    print(\"Test f1m: \", f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro'))\n",
    "    test_avg.append(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(\"Final avg: \", sum(test_avg)/10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (E9) With features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [list(sum(g.node_features).numpy()) for g in mutag_graphs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf = copy.deepcopy(X)\n",
    "for i in range(len(X)):\n",
    "    Xf[i].extend(features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final avg:  0.8833333333333334 0.0840708108356753\n",
      "CPU times: user 21 ms, sys: 3.28 ms, total: 24.3 ms\n",
      "Wall time: 23.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_avg = []\n",
    "for i in range (1,11):\n",
    "    with open(\"../data/MUTAG/10fold_idx/test_idx-{}.txt\".format(i), \"r\") as test_f,\\\n",
    "         open(\"../data/MUTAG/10fold_idx/train_idx-{}.txt\".format(i), \"r\") as train_f:\n",
    "        train_idx = [int(i) for i in train_f.readlines()]\n",
    "        test_idx = [int(i) for i in test_f.readlines()]\n",
    "        X_train = [Xf[i] for i in train_idx]\n",
    "        X_test = [Xf[i] for i in test_idx]\n",
    "        y_train = [y[i] for i in train_idx]\n",
    "        y_test = [y[i] for i in test_idx]\n",
    "        normalizer = Normalizer().fit(X_train)\n",
    "        X_train = normalizer.transform(X_train)\n",
    "        X_test = normalizer.transform(X_test)\n",
    "    clf = svm.SVC(C=10.0, kernel='rbf', degree=2, gamma='scale', \n",
    "              coef0=0.0, shrinking=True, probability=False, tol=0.001, \n",
    "              cache_size=200, class_weight=None, verbose=False, max_iter=-1, \n",
    "              decision_function_shape='ovr', random_state=None)\n",
    "    clf.fit(X_train, y_train)  \n",
    "    #print(\"Train: \", f1_score(y_pred=clf.predict(X_train), y_true=y_train, average='micro'))\n",
    "    #print(\"Test: \", f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='micro'))\n",
    "    test_avg.append(f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='micro'))\n",
    "print(\"Final avg: \", np.mean(test_avg), np.std(test_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
